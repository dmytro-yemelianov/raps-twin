FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04

WORKDIR /app

# Install Python and system dependencies
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1
RUN update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1

# Install llama-cpp-python with CUDA support
RUN CMAKE_ARGS="-DLLAMA_CUDA=on" pip install --no-cache-dir llama-cpp-python[cuda]>=0.2.0

# Install minimal dependencies for HTTP server
RUN pip install --no-cache-dir fastapi uvicorn[standard] pydantic

# Copy LLM service script
COPY docker/tier1_server.py .

# Create models directory
RUN mkdir -p /app/models

# Expose service port
EXPOSE 8001

# Run the LLM service
CMD ["python", "tier1_server.py"]
